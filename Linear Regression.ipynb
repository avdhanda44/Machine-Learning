{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a61e681a",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #FFE4E1; padding: 20px; border: 3px solid #FF69B4; border-radius: 10px; box-shadow: 0 0 10px rgba(0, 0, 0, 0.2);\">\n",
    "  <h1 style=\"color: #FF69B4; text-align: center; font-size: 36px; font-family: 'Arial', sans-serif;\">Linear Regression</h1>\n",
    "\n",
    "  <p style=\"font-family: 'Arial', sans-serif; font-size: 16px; line-height: 1.6;\">\n",
    "    Linear regression is a supervised learning algorithm used for predicting continuous numerical values. It aims to establish a linear relationship between the input features and the target variable. The fundamental concept behind linear regression is to fit a line (or hyperplane in higher dimensions) that best represents the relationship between the input features and the target variable.\n",
    "  </p>\n",
    "\n",
    "  <p style=\"font-family: 'Arial', sans-serif; font-size: 16px; line-height: 1.6;\">\n",
    "    In linear regression, the algorithm tries to find the best-fit line by minimizing a cost function.\n",
    "  </p>\n",
    "\n",
    "  <h3 style=\"color: #FF69B4; font-family: 'Arial', sans-serif; font-size: 24px; margin-top: 20px;\">Cost function: J(theta) in linear regression</h3>\n",
    "  <p style=\"font-family: 'Arial', sans-serif; font-size: 16px; line-height: 1.6;\">\n",
    "    It is derived from the MSE and is used to describe the cost function in terms of the model parameters theta.\n",
    "  </p>\n",
    "\n",
    "  <p style=\"font-family: 'Arial', sans-serif; font-size: 16px; line-height: 1.6;\">\n",
    "    J(theta) = (1/2m) * Σ(hθ(xᵢ) - yᵢ)²\n",
    "  </p>\n",
    "\n",
    "  <h3 style=\"color: #FF69B4; font-family: 'Arial', sans-serif; font-size: 24px; margin-top: 20px;\">Mean Squared Error (MSE)</h3>\n",
    "  <p style=\"font-family: 'Arial', sans-serif; font-size: 16px; line-height: 1.6;\">\n",
    "    The MSE measures the average squared difference between the predicted values and the actual values.\n",
    "  </p>\n",
    "\n",
    "  <p style=\"font-family: 'Arial', sans-serif; font-size: 16px; line-height: 1.6;\">\n",
    "    MSE = (1/n) * Σ(yᵢ - ŷᵢ)²\n",
    "  </p>\n",
    "\n",
    "  <p style=\"font-family: 'Arial', sans-serif; font-size: 16px; line-height: 1.6;\">\n",
    "    where,\n",
    "    <br>\n",
    "    - n is the number of training examples,\n",
    "    <br>\n",
    "    - yᵢ is the actual value,\n",
    "    <br>\n",
    "    - ŷᵢ is the predicted value for the i-th training example.\n",
    "  </p>\n",
    "\n",
    "  <p style=\"font-family: 'Arial', sans-serif; font-size: 16px; line-height: 1.6;\">\n",
    "    The linear regression algorithm works by adjusting the parameters (slope and intercept) of the line to minimize the MSE. This adjustment is performed using an optimization algorithm called gradient descent.\n",
    "  </p>\n",
    "\n",
    "  <h3 style=\"color: #FF69B4; font-family: 'Arial', sans-serif; font-size: 24px; margin-top: 20px;\">Gradient Descent</h3>\n",
    "  <p style=\"font-family: 'Arial', sans-serif; font-size: 16px; line-height: 1.6;\">\n",
    "    Gradient descent iteratively updates the parameters based on the gradients of the cost function with respect to the parameters, gradually converging towards the optimal values that minimize the MSE.\n",
    "  </p>\n",
    "\n",
    "  <p style=\"font-family: 'Arial', sans-serif; font-size: 16px; line-height: 1.6;\">\n",
    "    theta = theta - alpha * ∇J(theta)\n",
    "    <br>\n",
    "    theta₀ := theta₀ - alpha * (1/m) * Σ(h(xᵢ) - yᵢ)\n",
    "    <br>\n",
    "    theta₁ := theta₁ - alpha * (1/m) * Σ((h(xᵢ) - yᵢ) * xᵢ)\n",
    "  </p>\n",
    "\n",
    "  <p style=\"font-family: 'Arial', sans-serif; font-size: 16px; line-height: 1.6;\">\n",
    "    To check the efficiency of the linear regression model, several evaluation metrics can be used. Some commonly used metrics include:\n",
    "  </p>\n",
    "\n",
    "  <ol style=\"font-family: 'Arial', sans-serif; font-size: 16px; line-height: 1.6;\">\n",
    "    <li>Mean Absolute Error (MAE): It measures the average absolute difference between the predicted and actual values.</li>\n",
    "    <li>Root Mean Squared Error (RMSE): It is the square root of the MSE and provides a measure of the average magnitude of the prediction errors.</li>\n",
    "    <li>R-squared (R²) Score: It represents the proportion of the variance in the target variable that is predictable from the input features. R² score ranges from 0 to 1, with higher values indicating a better fit.</li>\n",
    "  </ol>\n",
    "\n",
    "  <p style=\"font-family: 'Arial', sans-serif; font-size: 16px; line-height: 1.6;\">\n",
    "    To improve the efficiency of linear regression, several techniques can be employed, such as:\n",
    "  </p>\n",
    "\n",
    "  <ul style=\"font-family: 'Arial', sans-serif; font-size: 16px; line-height: 1.6;\">\n",
    "    <li>Feature Scaling: Standardizing or normalizing the input features can help improve the efficiency and convergence speed of the algorithm.</li>\n",
    "    <li>Feature Engineering: Creating new features or transforming existing features can enhance the linear relationship between the inputs and the target variable.</li>\n",
    "    <li>Regularization Techniques: Adding regularization terms like L1 or L2 regularization can prevent overfitting by penalizing large coefficient values.</li>\n",
    "    <li>Handling Outliers: Removing or treating outliers in the dataset can improve the model's performance.</li>\n",
    "    <li>Polynomial Regression: Transforming the input features by adding polynomial terms can capture nonlinear relationships between the features and the target variable.</li>\n",
    "  </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d34a5d",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #F0FFF0; padding: 20px; border: 3px solid #98FB98; border-radius: 10px; box-shadow: 0 0 10px rgba(0, 0, 0, 0.2);\">\n",
    "  <h2 style=\"color: #2E8B57; font-family: 'Helvetica', sans-serif; font-size: 24px; margin-bottom: 20px; text-align: center;\">Lasso Regression (L1) and Ridge Regression (L2)</h2>\n",
    "\n",
    "  <p style=\"font-family: 'Helvetica', sans-serif; font-size: 18px; line-height: 1.6;\">\n",
    "    These are regularization techniques used in linear regression to mitigate overfitting and improve the model's performance. They involve adding a penalty term to the cost function that encourages the model to have smaller coefficient values.\n",
    "  </p>\n",
    "\n",
    "  <h3 style=\"color: #2E8B57; font-family: 'Helvetica', sans-serif; font-size: 20px; margin-top: 20px;\">1. L1 Regression (Lasso Regression)</h3>\n",
    "  <ul style=\"font-family: 'Helvetica', sans-serif; font-size: 18px; line-height: 1.6;\">\n",
    "    <li>\n",
    "      Lasso regression adds an L1 regularization term to the cost function, which is the sum of the absolute values of the coefficients multiplied by a regularization parameter (lambda).\n",
    "    </li>\n",
    "    <li>\n",
    "      The L1 regularization term encourages sparsity in the coefficient values, meaning it tends to drive some coefficients to exactly zero, effectively selecting a subset of features.\n",
    "    </li>\n",
    "    <li>\n",
    "      L1 regularization can be useful in feature selection and reducing model complexity.\n",
    "    </li>\n",
    "    <li>\n",
    "      It tends to be more effective when there is a need for feature selection or when there are many irrelevant features.\n",
    "    </li>\n",
    "  </ul>\n",
    "\n",
    "  <h3 style=\"color: #2E8B57; font-family: 'Helvetica', sans-serif; font-size: 20px; margin-top: 20px;\">2. L2 Regression (Ridge Regression)</h3>\n",
    "  <ul style=\"font-family: 'Helvetica', sans-serif; font-size: 18px; line-height: 1.6;\">\n",
    "    <li>\n",
    "      Ridge regression adds an L2 regularization term to the cost function, which is the sum of the squared values of the coefficients multiplied by a regularization parameter (lambda).\n",
    "    </li>\n",
    "    <li>\n",
    "      The L2 regularization term encourages the coefficient values to be small but does not drive them to exactly zero. It helps in reducing the impact of multicollinearity and stabilizing the model.\n",
    "    </li>\n",
    "    <li>\n",
    "      L2 regularization can help in improving the overall generalization of the model.\n",
    "    </li>\n",
    "    <li>\n",
    "      It is often used when dealing with multicollinearity issues or when a more stable model is required.\n",
    "    </li>\n",
    "  </ul>\n",
    "\n",
    "  <p style=\"font-family: 'Helvetica', sans-serif; font-size: 18px; line-height: 1.6; margin-top: 20px;\">\n",
    "    In both Lasso and Ridge regression, lambda (λ) is the regularization parameter that controls the strength of regularization. By tuning this parameter, you can control the amount of regularization applied. A larger lambda value increases the penalty, leading to stronger regularization and smaller coefficient values.\n",
    "  </p>\n",
    "\n",
    "  <p style=\"font-family: 'Helvetica', sans-serif; font-size: 18px; line-height: 1.6;\">\n",
    "    It's worth noting that both Lasso and Ridge regression techniques have variants that combine the benefits of both approaches, such as Elastic Net regression, which adds a combination of L1 and L2 regularization terms to the cost function.\n",
    "  </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0104ac",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #FFFFE0; padding: 20px; border: 3px solid #FFD700; border-radius: 10px; box-shadow: 0 0 10px rgba(0, 0, 0, 0.2);\">\n",
    "  <h2 style=\"color: #FFD700; font-family: 'Arial', sans-serif; font-size: 24px; margin-bottom: 20px; text-align: center;\">Adjusted R-squared</h2>\n",
    "\n",
    "  <p style=\"font-family: 'Arial', sans-serif; font-size: 18px; line-height: 1.6;\">\n",
    "    It is a modification of the R-squared (R²) metric that takes into account the number of predictors (independent variables) in a linear regression model. While R² measures the proportion of variance explained by the predictors, adjusted R-squared adjusts for the complexity of the model by penalizing the addition of unnecessary predictors.\n",
    "  </p>\n",
    "\n",
    "  <p style=\"font-family: 'Arial', sans-serif; font-size: 18px; line-height: 1.6;\">\n",
    "    <strong>Adjusted R² = 1 - [(1 - R²) * (n - 1) / (n - k - 1)]</strong>\n",
    "  </p>\n",
    "\n",
    "  <p style=\"font-family: 'Arial', sans-serif; font-size: 18px; line-height: 1.6;\">\n",
    "    Where:\n",
    "  </p>\n",
    "  <ul style=\"font-family: 'Arial', sans-serif; font-size: 18px; line-height: 1.6;\">\n",
    "    <li><i>R² represents the R-squared value of the model.</i></li>\n",
    "    <li><i>n is the number of data points (observations) in the dataset.</i></li>\n",
    "    <li><i>k is the number of predictors (independent variables) in the model.</i></li>\n",
    "  </ul>\n",
    "\n",
    "  <p style=\"font-family: 'Arial', sans-serif; font-size: 18px; line-height: 1.6;\">\n",
    "    The adjusted R-squared value ranges from negative infinity to 1. A higher adjusted R-squared indicates a better fit of the model, taking into account both the goodness of fit (R-squared) and the complexity of the model (number of predictors).\n",
    "  </p>\n",
    "\n",
    "  <p style=\"font-family: 'Arial', sans-serif; font-size: 18px; line-height: 1.6;\">\n",
    "    By penalizing the addition of unnecessary predictors, the adjusted R-squared helps prevent overfitting, which occurs when a model fits the training data too closely but fails to generalize well to new, unseen data. It provides a more conservative measure of model performance by considering the trade-off between model complexity and the amount of explained variance.\n",
    "  </p>\n",
    "\n",
    "  <p style=\"font-family: 'Arial', sans-serif; font-size: 18px; line-height: 1.6;\">\n",
    "    When comparing models with different numbers of predictors, the adjusted R-squared can be used to select the model that balances simplicity and predictive power. Models with a higher adjusted R-squared, while having fewer predictors, are generally preferred as they explain a larger proportion of the variation in the dependent variable while avoiding overfitting.\n",
    "  </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e749acb",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #F0F8FF; padding: 20px; border: 3px solid #87CEEB; border-radius: 10px; box-shadow: 0 0 10px rgba(0, 0, 0, 0.2);\">\n",
    "  <h2 style=\"color: #87CEEB; font-family: 'Arial', sans-serif; font-size: 24px; margin-bottom: 20px; text-align: center;\">Linear Regression Limitations</h2>\n",
    "\n",
    "  <ol style=\"font-family: 'Arial', sans-serif; font-size: 18px; line-height: 1.6;\">\n",
    "    <li><strong>Linearity Assumption:</strong> Linear regression assumes a linear relationship between the independent variables and the dependent variable. If the true relationship is nonlinear, linear regression may provide a poor fit and inaccurate predictions.</li>\n",
    "    <li><strong>Assumption of Independence:</strong> Linear regression assumes that the observations are independent of each other. If there is autocorrelation or dependence among the data points, such as in time series data, linear regression may yield biased and inefficient estimates.</li>\n",
    "    <li><strong>Outliers and Influential Points:</strong> Linear regression is sensitive to outliers and influential data points that have a disproportionate impact on the model's parameters. Outliers can significantly affect the estimated coefficients and distort the model's predictions.</li>\n",
    "    <li><strong>Assumption of Homoscedasticity:</strong> Linear regression assumes that the variance of the errors (residuals) is constant across all levels of the independent variables. If the residuals exhibit heteroscedasticity, meaning that the variance systematically changes, the model may produce inefficient and biased estimates.</li>\n",
    "    <li><strong>Multicollinearity:</strong> Linear regression assumes that the independent variables are not highly correlated with each other (multicollinearity). When multicollinearity is present, it becomes challenging to determine the individual effects of the variables on the dependent variable accurately.</li>\n",
    "    <li><strong>Non-Gaussian Errors:</strong> Linear regression assumes that the errors follow a Gaussian (normal) distribution. If the errors are non-Gaussian, such as skewed or heavy-tailed distributions, the statistical inferences and hypothesis tests may be affected.</li>\n",
    "    <li><strong>Limited Flexibility:</strong> Linear regression assumes a linear relationship between the predictors and the response variable. It may not capture complex nonlinear patterns, interactions, or higher-order relationships without explicit transformations or feature engineering.</li>\n",
    "    <li><strong>Overfitting or Underfitting:</strong> Linear regression can suffer from overfitting or underfitting if the model is too simple or too complex, respectively. It is essential to strike the right balance and choose appropriate model complexity based on the problem and available data.</li>\n",
    "  </ol>\n",
    "\n",
    "  <p style=\"font-family: 'Arial', sans-serif; font-size: 18px; line-height: 1.6;\">\n",
    "    Despite these limitations, linear regression remains a widely used and interpretable method for modeling relationships between variables. However, it is important to assess these limitations and consider alternative models or techniques when necessary.\n",
    "  </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c9ce273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d381c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#house Pricing dataset\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c46c7468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anuradhadhanda/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df=load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "742026c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.DataFrame(df.data)\n",
    "dataset.columns=df.feature_names\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac1bf290",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Price']=df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14d3db7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  Price  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69128599",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dividing the  dataset into independent and dependent features\n",
    "X=dataset.iloc[:,:-1]##independent features\n",
    "y=dataset.iloc[:,-1]## dependent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c14c2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d548bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2585982e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-25.187874739284993\n"
     ]
    }
   ],
   "source": [
    "##Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "lin_reg=LinearRegression()\n",
    "lin_reg.fit(X_train,y_train)\n",
    "mse=cross_val_score(lin_reg,X_train,y_train,scoring='neg_mean_squared_error',cv=5)\n",
    "mean_mse=np.mean(mse)\n",
    "print(mean_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75de0275",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a83b2416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b899c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score1=r2_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99e5151c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6709558976744436\n"
     ]
    }
   ],
   "source": [
    "print(r2_score1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
